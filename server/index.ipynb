{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print( np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from pyngrok import ngrok\n",
    "from tensorflow import keras\n",
    "from google.transliteration import transliterate_word ## not installed\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences ## causing issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 15:30:42.088148: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-12 15:30:42.088193: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-02-12 15:30:42.422372: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:42.678574: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:42.746740: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:42.770386: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:42.776794: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:43.182667: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:43.189067: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:43.209851: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:43.216352: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:43.467941: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:43.474403: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:43.700877: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:43.872999: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-02-12 15:30:43.879364: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15 6682 4934\n",
      "['यह हमारे देश के लिए वास्तव में अनिवार्य वस्तु है.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 15:30:45.395475: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-12 15:30:45.783470: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-12 15:30:45.954760: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the to for to to to to to for for for for content content content\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 15:30:46.124488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model_size='15000'\n",
    "\n",
    "def load_models_and_parameters(model_size):\n",
    "\n",
    "    path=model_size+'/'\n",
    "\n",
    " \n",
    "    model = keras.models.load_model(path+'lstm_model')\n",
    "    with open(path+ \"src_parameters.pickle\", 'rb') as handle:\n",
    "        src_parameters = pickle.load(handle)\n",
    "\n",
    "    with open(path+ \"src_tokenizer.pickle\", 'rb') as handle:\n",
    "        src_tokenizer = pickle.load(handle)\n",
    "\n",
    "    with open(path+ \"target_parameters.pickle\", 'rb') as handle:\n",
    "        target_parameters = pickle.load(handle)\n",
    "\n",
    "    with open(path+ \"target_tokenizer.pickle\", 'rb') as handle:\n",
    "        target_tokenizer = pickle.load(handle)\n",
    "    return model, src_tokenizer, target_tokenizer, src_parameters, target_parameters\n",
    "\n",
    "model_path=    \"../machine-learning/model/lstm/\" +model_size\n",
    "model, src_tokenizer, target_tokenizer, src_parameters, target_parameters= load_models_and_parameters(model_path)\n",
    "\n",
    "\n",
    "\n",
    "src_length=src_parameters[\"src_length\"]\n",
    "src_vocab_size=src_parameters[\"src_vocab_size\"]\n",
    "\n",
    "target_length=target_parameters[\"target_length\"]\n",
    "target_vocab_size=target_parameters[\"target_vocab_size\"]\n",
    "\n",
    "print(src_length, target_length, src_vocab_size, target_vocab_size)\n",
    "\n",
    "def encode_sequences(tokenizer, length, lines):  ## pass src_tokenizer for tokenizer\n",
    "    # encode and pad sequences\n",
    "    X = tokenizer.texts_to_sequences(lines) # integer encode sequences\n",
    "    X = pad_sequences(X, maxlen=length, padding='post') # pad sequences with 0 values\n",
    "    return X\n",
    "\n",
    "def word_for_id(integer, tokenizer):\n",
    "    # map an integer to a word\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    " \n",
    "def predict_seq(model, tokenizer, source):  ## pass target_tokenizer for tokenizer\n",
    "    # generate target from a source sequence\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [np.argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)\n",
    "\n",
    "\n",
    "transliterate_eng_hindi = transliterate_word('yah hamaare desh ke lie vaastav mein anivaary vastu hai.', lang_code='hi', max_suggestions=1)\n",
    "print(transliterate_eng_hindi)\n",
    "\n",
    "encoded_hindi = encode_sequences(src_tokenizer, src_length, transliterate_eng_hindi)\n",
    "\n",
    "\n",
    "source= encoded_hindi\n",
    "tar_tokenizer=target_tokenizer\n",
    "\n",
    "translation = predict_seq(model, tar_tokenizer, source)\n",
    "print(translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e85fb0000938f5e2a29218cbc508a2e9fdbb88a8d53596d72d5192ab39b6de65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
