{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk-UGKLoF0pz"
      },
      "source": [
        "### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6j5SP-3F0p2"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAj05h9bGf6_"
      },
      "source": [
        "## Read IIT Data Bombay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "d04e9d39206d4a5abc3e49deefd4c949",
            "372afca9149a4cd3b3fface06b846b66",
            "475553cf8de34e6e96adabc0668dc7f9",
            "f9f40bd818f040d88306317e3af3b76f",
            "3ba067e90088413d8bf6aca9015f4095",
            "91d85c57d43540e0949b8c04a8260ba7",
            "a6fb3097f1e64e36a2cd8c282e12e753",
            "f903ee0ef410462782695068ee43853e",
            "531f0b44e0694b9f994a55bda70f1095",
            "a92b851b580b4d5584adea05e8ab8d85",
            "e62e670d14744ab98a32e83f74126f62"
          ]
        },
        "id": "1n3SFll_Gjje",
        "outputId": "a31ac1f6-3947-4bcb-d688-36526dbecf53"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets==1.18.1\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"cfilt/iitb-english-hindi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVDGNU3-I07s"
      },
      "outputs": [],
      "source": [
        "data_size=15000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1gpyYyrIyPU"
      },
      "outputs": [],
      "source": [
        "hin_eng=[]\n",
        "for translation_pair in dataset[\"train\"][\"translation\"][:15000]:\n",
        "  source_sentence = translation_pair[\"hi\"]\n",
        "  target_sentence = translation_pair[\"en\"]\n",
        "  hin_eng.append([target_sentence, source_sentence ])\n",
        "\n",
        "hin_eng = array(hin_eng)\n",
        "del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTycI1zrF0p7"
      },
      "source": [
        "### Text Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBLIYdOsF0p7"
      },
      "source": [
        "#### Text Cleaning\n",
        "\n",
        "Let's take a look at our data, then we will decide which pre-processing steps to adopt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHMOzQ3VF0p8"
      },
      "source": [
        "We will get rid of the punctuation marks, and then convert the text to lower case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOM5bqTKF0p8"
      },
      "outputs": [],
      "source": [
        "# Remove punctuation\n",
        "hin_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in hin_eng[:,0]]\n",
        "hin_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in hin_eng[:,1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0c4QmEaF0p8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# convert to lowercase\n",
        "for i in range(len(hin_eng)):\n",
        "    hin_eng[i,0] = hin_eng[i,0].lower()\n",
        "    \n",
        "    hin_eng[i,1] = hin_eng[i,1].lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LOHq9wNF0p9"
      },
      "source": [
        "#### Text to Sequence Conversion\n",
        "\n",
        "To feed our data in a Seq2Seq model, we will have to convert both the input and the output sentences into integer sequences of fixed length. Before that, let's visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and German, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaLSLBgjF0p9"
      },
      "outputs": [],
      "source": [
        "# empty lists\n",
        "eng_l = []\n",
        "deu_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in hin_eng[:,0]:\n",
        "    eng_l.append(len(i.split()))\n",
        "\n",
        "for i in hin_eng[:,1]:\n",
        "    deu_l.append(len(i.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HewOsT1sF0p9"
      },
      "outputs": [],
      "source": [
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "mM3yMDUPF0p9",
        "outputId": "d22f777e-9193-44ab-e5bf-86863546ba33"
      },
      "outputs": [],
      "source": [
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eeBzSL2F0p9"
      },
      "source": [
        "The maximum length of the German sentences is 11 and that of the English phrases is 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-miOgiQMF0p-"
      },
      "source": [
        "Let's vectorize our text data by using Keras's Tokenizer() class. It will turn our sentences into sequences of integers. Then we will pad those sequences with zeros to make all the sequences of same length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ol7HLbcYF0p-"
      },
      "outputs": [],
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf-Ik-KoF0p-",
        "outputId": "e3c4a4a1-c46c-4eeb-edca-8b844472e0aa"
      },
      "outputs": [],
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(hin_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6J0EQQjF0p-",
        "outputId": "1bbdc5b8-2f5d-4d0a-eff2-ee64fc831d5f"
      },
      "outputs": [],
      "source": [
        "# prepare Deutch tokenizer\n",
        "deu_tokenizer = tokenization(hin_eng[:, 1])\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "\n",
        "deu_length = 8\n",
        "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk5ico_tF0p-"
      },
      "source": [
        "Given below is a function to prepare the sequences. It will also perform sequence padding to a maximum sentence length as mentioned above. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnSeK3fkF0p-"
      },
      "outputs": [],
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41oaGLouF0p_"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlxuCqt9F0p_"
      },
      "source": [
        "We will now split the data into train and test set for model training and evaluation, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqNf6Xd4F0p_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(hin_eng, test_size=0.2, random_state = 12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqNlRRtSF0p_"
      },
      "source": [
        "It's time to encode the sentences. We will encode German sentences as the input sequences and English sentences as the target sequences. It will be done for both train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4toYgR08F0p_"
      },
      "outputs": [],
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPDRy206F0p_"
      },
      "outputs": [],
      "source": [
        "# prepare validation data\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu3fhH1KF0p_"
      },
      "source": [
        "Now comes the exciting part! Let us define our Seq2Seq model architecture. We are using an Embedding layer and an LSTM layer as our encoder and another LSTM layer followed by a Dense layer as the decoder.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz5u6G2kF0p_"
      },
      "outputs": [],
      "source": [
        "# build NMT model\n",
        "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "    model.add(LSTM(units))\n",
        "    model.add(RepeatVector(out_timesteps))\n",
        "    model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(Dense(out_vocab, activation='softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUMv-csHF0p_"
      },
      "source": [
        "We are using RMSprop optimizer in this model as it is usually a good choice for recurrent neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqSTctefF0p_"
      },
      "outputs": [],
      "source": [
        "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoxowjvfF0p_"
      },
      "source": [
        "Please note that we have used __'sparse_categorical_crossentropy'__ as the loss function because it allows us to use the target sequence as it is instead of one hot encoded format. One hot encoding the target sequences with such a huge vocabulary might consume our system's entire memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVqqUb8JF0p_"
      },
      "source": [
        "It seems we are all set to start training our model. We will train it for 30 epochs and with a batch size of 512. You may change and play these hyperparameters. We will also be using __ModelCheckpoint()__ to save the best model with lowest validation loss. I personally prefer this method over early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYxTsmzAF0qA",
        "outputId": "3f88ba9d-cdcb-4176-b1cf-cb7a5893aae8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "filename = 'model.h1.27_nov_22'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
        "          epochs=30, batch_size=512, \n",
        "          validation_split = 0.2,\n",
        "          callbacks=[checkpoint], verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jIL72MyF0qA"
      },
      "source": [
        "Let's compare the training loss and the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfGGP-DTF0qA",
        "outputId": "e112d54c-a669-4b5e-9c8a-a3b2384f4042"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmOHUaoTF0qA"
      },
      "source": [
        "### Make Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se_1LpmuF0qA"
      },
      "source": [
        "Let's load the saved model to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojhmagyfF0qA"
      },
      "outputs": [],
      "source": [
        "model = load_model('model.h1.24_jan_19')\n",
        "# preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))\n",
        "preds = (model.predict(testX.reshape((testX.shape[0],testX.shape[1]))) > 0.5).astype(\"int32\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sp9hwldGF0qA"
      },
      "outputs": [],
      "source": [
        "# def get_word(n, tokenizer):\n",
        "#     for word, index in tokenizer.word_index.items():\n",
        "#         if index == n.all():\n",
        "#             return word\n",
        "#     return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_word(n, tokenizer):\n",
        "    for word, index in list(tokenizer.word_index.items()):\n",
        "        print(n)\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "preds=preds[:10]\n",
        "print(preds[0][0])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "items = list(eng_tokenizer.word_index.items())\n",
        "for tuple, index  in items:\n",
        "    print(index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Idea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds[6][0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKvTM40VF0qA"
      },
      "outputs": [],
      "source": [
        "# convert predictions into text (English)\n",
        "preds_text = []\n",
        "c=0\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], eng_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "             \n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)            \n",
        "    print('Result: ', c, ' '.join(temp))    \n",
        "    c=c+1\n",
        "    preds_text.append(' '.join(temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "( test[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYgTA1BnF0qA"
      },
      "outputs": [],
      "source": [
        "# pred_df = pd.DataFrame({'actual' : test[:,1], 'predicted' : preds_text})\n",
        "pred_df = pd.DataFrame({'actual' : test[:,1], 'predicted' : preds_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_BxjrM4F0qA"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL_kCMVmF0qB",
        "outputId": "6817c9be-f75e-4de2-b2c0-5e332c44cd75"
      },
      "outputs": [],
      "source": [
        "pred_df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewyHW9NJF0qB",
        "outputId": "433014b4-b7ea-4761-983d-538596ea34a6"
      },
      "outputs": [],
      "source": [
        "pred_df.tail(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHXe_VZzF0qB",
        "outputId": "2ae344ba-2365-4a37-c632-82de008cef68"
      },
      "outputs": [],
      "source": [
        "pred_df.tail(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZokNLFBF0qB",
        "outputId": "119c71c4-c39b-4e69-f3c9-86325e50c4c0"
      },
      "outputs": [],
      "source": [
        "pred_df.sample(15)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Display Kernel Name is Kanye ",
      "language": "python",
      "name": "west-kanye"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "231fa661f6864ef19e499bbd2782d03ff99f363f5ebfe416ba9cf7c065dc127b"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "372afca9149a4cd3b3fface06b846b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91d85c57d43540e0949b8c04a8260ba7",
            "placeholder": "​",
            "style": "IPY_MODEL_a6fb3097f1e64e36a2cd8c282e12e753",
            "value": "100%"
          }
        },
        "3ba067e90088413d8bf6aca9015f4095": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "475553cf8de34e6e96adabc0668dc7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f903ee0ef410462782695068ee43853e",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_531f0b44e0694b9f994a55bda70f1095",
            "value": 3
          }
        },
        "531f0b44e0694b9f994a55bda70f1095": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91d85c57d43540e0949b8c04a8260ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6fb3097f1e64e36a2cd8c282e12e753": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a92b851b580b4d5584adea05e8ab8d85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d04e9d39206d4a5abc3e49deefd4c949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_372afca9149a4cd3b3fface06b846b66",
              "IPY_MODEL_475553cf8de34e6e96adabc0668dc7f9",
              "IPY_MODEL_f9f40bd818f040d88306317e3af3b76f"
            ],
            "layout": "IPY_MODEL_3ba067e90088413d8bf6aca9015f4095"
          }
        },
        "e62e670d14744ab98a32e83f74126f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f903ee0ef410462782695068ee43853e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f40bd818f040d88306317e3af3b76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92b851b580b4d5584adea05e8ab8d85",
            "placeholder": "​",
            "style": "IPY_MODEL_e62e670d14744ab98a32e83f74126f62",
            "value": " 3/3 [00:01&lt;00:00,  2.18it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
