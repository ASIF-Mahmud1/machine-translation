{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/learn/Desktop/Projects/machine-translation/machine-learning/train/lstm', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/venv/lib/python39.zip', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/venv/lib/python3.9', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/venv/lib/python3.9/lib-dynload', '', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/venv/lib/python3.9/site-packages']\n",
      "['/Users/learn/Desktop/Projects/machine-translation/machine-learning/train/lstm', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/venv/lib/python39.zip', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/venv/lib/python3.9', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/venv/lib/python3.9/lib-dynload', '', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/venv/lib/python3.9/site-packages', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/helper', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/utils', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/test/helper', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/utils', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/data', '/Users/learn/Desktop/Projects/machine-translation/machine-learning/train/lstm/create-model/lstm']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "def printmd(string):\n",
    "    # Print with Markdowns    \n",
    "    display(Markdown(string))\n",
    "\n",
    "    \n",
    "def handle_helper_functions():\n",
    "    print(sys.path)\n",
    "    directory_path = os.path.abspath(os.path.join('../../helper'))\n",
    "    if directory_path not in sys.path:\n",
    "        sys.path.append(directory_path)    \n",
    "\n",
    "    translation_path=os.path.abspath(os.path.join('../../utils')) \n",
    "    if translation_path not in sys.path:\n",
    "        sys.path.append(translation_path)   \n",
    "    sys.path.append('/Users/learn/Desktop/Projects/machine-translation/machine-learning/test/helper')                                       \n",
    "    sys.path.append('/Users/learn/Desktop/Projects/machine-translation/machine-learning/utils')\n",
    "    sys.path.append('/Users/learn/Desktop/Projects/machine-translation/machine-learning/data')\n",
    "\n",
    "\n",
    "    lstm_helper_path = os.path.abspath(os.path.join('./create-model/lstm/'))\n",
    "    if lstm_helper_path not in sys.path:\n",
    "        sys.path.append(lstm_helper_path)    \n",
    "\n",
    "    print(sys.path)\n",
    "    \n",
    "\n",
    "handle_helper_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration cfilt--iitb-english-hindi-911387c6837f8b91\n",
      "Reusing dataset parquet (/Users/learn/.cache/huggingface/datasets/parquet/cfilt--iitb-english-hindi-911387c6837f8b91/0.0.0/1638526fd0e8d960534e2155dc54fdff8dce73851f21f031d2fb9c2cf757c121)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e5554600f7423ba4cdc436cf5f0d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from iit_dataset import createDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator():\n",
    "    def __init__(self, training_size=10000) -> None:\n",
    "        self.training_size=training_size\n",
    "        self.idx_src=0\n",
    "        self.idx_tar = 1\n",
    "        pass\n",
    "    def train_model(self):\n",
    "        ''' \n",
    "        GET TRAINING DATA FROM IIT DATASET\n",
    "        TURN THEM INTO VECTORS\n",
    "        CREATE ENCODER DICTIONARY \n",
    "        SAVE THEM INSIDE THE CLASS\n",
    "        '''\n",
    "        pass\n",
    "    def _get_training_data(self):\n",
    "        pool_oftexts, pairs =createDataset(data_size=self.training_size, type=\"train\")\n",
    "        dataset= pool_oftexts\n",
    "        return dataset\n",
    "    \n",
    "    def _get_train_test_split(self):\n",
    "        dataset= self._get_training_data()\n",
    "        total_sentences= len(dataset)\n",
    "        test_proportion = 0.1\n",
    "        train_test_threshold = int( (1-test_proportion) * total_sentences)\n",
    "\n",
    "        dataset[\"eng\"] = dataset[\"eng\"].apply(lambda x: self.clean(x))\n",
    "        dataset[\"hindi\"] = dataset[\"hindi\"].apply(lambda x: self.clean(x))\n",
    "\n",
    "        dataset = dataset.values\n",
    "        dataset = dataset[:total_sentences]\n",
    "\n",
    "        train, test = dataset[:train_test_threshold], dataset[train_test_threshold:]\n",
    "\n",
    "        return train, test\n",
    "    \n",
    "    def clean(self,string):\n",
    "        string = string.replace(\"\\u202f\",\" \")\n",
    "        string = string.lower()\n",
    "        for p in punctuation + \"«»\" + \"0123456789\":\n",
    "            string = string.replace(p,\" \")  \n",
    "        string = re.sub('\\s+',' ', string)\n",
    "        string = string.strip()\n",
    "            \n",
    "        return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator= Translator(training_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translation",
   "language": "python",
   "name": "translation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
