{"cells":[{"cell_type":"markdown","metadata":{"id":"B453NNRC0joS"},"source":["# Load Model From Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24203,"status":"ok","timestamp":1666021278213,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"},"user_tz":-360},"id":"jvdaYoDtgQMT","outputId":"e4ff7a81-3e29-43c6-fa40-71af4996d124"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Initialize Paths of Models and Parameters"],"metadata":{"id":"5zoz2cQPKZtf"}},{"cell_type":"code","source":["path= \"/content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/\"\n","# copy file that has helper function\n","!cp '/content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/test/helper/score.py' .\n","\n","model_list=  [\"1000\",\"2908\",\"5000\",\"10000\"]"],"metadata":{"id":"MFKnZu9fKhqQ","executionInfo":{"status":"ok","timestamp":1666021605522,"user_tz":-360,"elapsed":486,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Install and Import Modules"],"metadata":{"id":"fLGZBCvrJC6X"}},{"cell_type":"code","source":["!pip install -q \"tensorflow==2.8.*\"\n","!pip install -q \"tensorflow-text==2.8.*\""],"metadata":{"id":"maOThzQQ43jO","executionInfo":{"status":"ok","timestamp":1666021370509,"user_tz":-360,"elapsed":91048,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca06c18c-91c3-48d3-949d-11e716c14913"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 497.9 MB 30 kB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 53.4 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 42.3 MB/s \n","\u001b[K     |████████████████████████████████| 462 kB 45.9 MB/s \n","\u001b[K     |████████████████████████████████| 4.9 MB 20.9 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"_Fo-82DfGVBw","executionInfo":{"status":"ok","timestamp":1666021374850,"user_tz":-360,"elapsed":4348,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.utils.vis_utils import plot_model\n","import pickle\n","from tensorflow.keras.layers import Input, Embedding,Dense,  LSTM\n","from tensorflow.keras import layers , activations , models , preprocessing , utils\n","from tensorflow.keras.models import load_model\n","import numpy as np\n","from nltk.translate.bleu_score import sentence_bleu\n","import pandas as pd\n","import tensorflow_text as text"]},{"cell_type":"code","source":["from score import get_cosine_val"],"metadata":{"id":"xKbFPJRpobr_","executionInfo":{"status":"ok","timestamp":1666021778554,"user_tz":-360,"elapsed":7,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["!pip install fasttext\n","import fasttext.util"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"snEbCRU_q38p","executionInfo":{"status":"ok","timestamp":1666021465162,"user_tz":-360,"elapsed":90322,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"b2ba9fa5-824b-4de7-ff45-a4966f9d3d65"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fasttext\n","  Downloading fasttext-0.9.2.tar.gz (68 kB)\n","\u001b[K     |████████████████████████████████| 68 kB 4.9 MB/s \n","\u001b[?25hCollecting pybind11>=2.2\n","  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3166309 sha256=47510c8a754e1e9b6dd94d25e93d5add8670b15b85cb0dbbc146a1b8d9422e48\n","  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n","Successfully built fasttext\n","Installing collected packages: pybind11, fasttext\n","Successfully installed fasttext-0.9.2 pybind11-2.10.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"PDoZgXN3uQJn"},"source":["# Download Sentences for Test"]},{"cell_type":"code","source":["!wget http://www.manythings.org/anki/hin-eng.zip -O hin-eng.zip\n","!unzip hin-eng.zip"],"metadata":{"id":"O8PEeQ4LY6Xg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Def. Get Summary Statistics for every model "],"metadata":{"id":"sAM8mvxHJPj3"}},{"cell_type":"code","source":["def get_model_statistics_summary(model_path,path_encoder_parameters,path_encoder_dictionary,path_decoder_parameters,path_decoder_dictionary, encoderPath, decoderPath ):\n","\n","################################## START  ##################################\n","    reconstructed_model = keras.models.load_model(model_path)\n","    plot_model(reconstructed_model, to_file='modelsummary.png', show_shapes=True, show_layer_names=True)\n","    reconstructed_model.summary()\n","\n","\n","    ## Load Dictionaries and Parameters \n","    path_encoder_parameters= path_encoder_parameters\n","    path_encoder_dictionary= path_encoder_dictionary\n","    path_decoder_parameters= path_decoder_parameters\n","    path_decoder_dictionary= path_decoder_dictionary\n","\n","    # loading\n","    with open(path_encoder_parameters, 'rb') as handle:\n","        encoder_parameters = pickle.load(handle)\n","\n","    # loading\n","    with open(path_encoder_dictionary, 'rb') as handle:\n","        encoder_dictionary = pickle.load(handle)\n","\n","    # loading\n","    with open(path_decoder_parameters, 'rb') as handle:\n","        decoder_parameters= pickle.load(handle)\n","\n","    # loading\n","    with open(path_decoder_dictionary, 'rb') as handle:\n","        decoder_dictionary = pickle.load(handle)    \n","\n","    print(encoder_parameters)\n","    # encoder_dictionary\n","    print(decoder_parameters)\n","    # decoder_dictionary\n","\n","    encoder_inputs = reconstructed_model.input[0]  # input_1\n","    encoder_outputs, state_h_enc, state_c_enc = reconstructed_model.layers[4].output  # lstm_1\n","    encoder_states = [state_h_enc, state_c_enc]\n","    encoder_model = keras.Model(encoder_inputs, encoder_states)\n","    latent_dim = 256  # Note: may be need to save in drive as well\n","\n","\n","    num_decoder_tokens =decoder_parameters['num_decoder_tokens']\n","    max_output_length= decoder_parameters['max_decoder_seq_length']\n","    max_input_length= encoder_parameters['max_encoder_seq_length']\n","\n","    encoder_word_dict=encoder_dictionary\n","    decoder_word_dict= decoder_dictionary\n","\n","\n","    decoder_inputs = Input(shape=( max_output_length , ))\n","    decoder_embedding = Embedding( num_decoder_tokens, 256 , mask_zero=True) (decoder_inputs)\n","\n","    decoder_lstm = LSTM( 256 , return_state=True , return_sequences=True , recurrent_dropout=0.2 , dropout=0.2)\n","    decoder_dense = Dense( num_decoder_tokens , activation=tf.keras.activations.softmax ) \n","\n","\n","    def str_to_tokens( sentence : str ):\n","        words = sentence.lower().split()\n","        tokens_list = list()\n","        for word in words:\n","                # print(\"word \", word, eng_word_dict.get(word,1) )\n","                my_word=  encoder_word_dict.get(word,1)\n","                tokens_list.append(my_word) \n","    \n","        return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_input_length , padding='post')\n","\n","\n","    def make_inference_models():\n","        \n","            encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n","            \n","            decoder_state_input_h = tf.keras.layers.Input(shape=( 256,))\n","            decoder_state_input_c = tf.keras.layers.Input(shape=( 256 ,))\n","            \n","            decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","            \n","            decoder_outputs, state_h, state_c = decoder_lstm(\n","                decoder_embedding , initial_state=decoder_states_inputs)\n","            decoder_states = [state_h, state_c]\n","            decoder_outputs = decoder_dense(decoder_outputs)\n","            decoder_model = tf.keras.models.Model(\n","                [decoder_inputs] + decoder_states_inputs,\n","                [decoder_outputs] + decoder_states)\n","            \n","            return encoder_model , decoder_model\n","\n","\n","    enc_model , dec_model = make_inference_models()\n","\n","\n","    # Test Previous Model\n","\n","\n","    encoderPath= encoderPath\n","    decoderPath= decoderPath\n","\n","    # loading\n","\n","    enc_model =  load_model(encoderPath)\n","    dec_model  =  load_model(decoderPath)\n","\n","    def translate_sentence(sentence):\n","        for epoch in range(1 ):\n","            states_values = enc_model.predict( str_to_tokens(sentence ) )\n","            empty_target_seq = np.zeros( ( 1 , 1 ) )\n","            empty_target_seq[0, 0] = decoder_word_dict['start']\n","            stop_condition = False\n","            decoded_translation = ''\n","            while not stop_condition :\n","                dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n","                sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n","                sampled_word = None\n","                for word , index in decoder_word_dict.items() :\n","                    if sampled_word_index == index :\n","                        decoded_translation += ' {}'.format( word )\n","                        sampled_word = word\n","                \n","                if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n","                    stop_condition = True\n","                    \n","                empty_target_seq = np.zeros( ( 1 , 1 ) )  \n","                empty_target_seq[ 0 , 0 ] = sampled_word_index\n","                states_values = [ h , c ] \n","\n","            # print(\"Decoded Traslation \", decoded_translation )\n","        return  decoded_translation\n","\n","################################## END  ##################################\n","\n","    ## Get sentences to test the model\n","\n","    lines = pd.read_table( 'hin.txt' , names=[ 'eng' , 'hindi' ] )\n","    lines.reset_index( level=0 , inplace=True )\n","    lines.rename( columns={ 'index' : 'eng' , 'eng' : 'hindi' , 'hindi' : 'c' } , inplace=True )\n","    lines = lines.drop( 'c' , 1 )  \n","\n","    sample_sentences= lines[-10:]\n","    sample_sentences\n","\n","    # Reference Token \n","\n","    reference_tokens=[]\n","\n","    for line in sample_sentences['eng']:\n","        # print( line.split() ) \n","        reference_tokens.append( line.split() )\n","\n","    df = pd.DataFrame(      columns=['reference', 'candidate', 'bleu_score'],  )\n","\n","    df[\"reference\"]= reference_tokens\n","\n","    ####### START Calculate Cosine Similarity for two sentences\n","    scores=[]\n","    for line in sample_sentences['eng']:\n","        translation= translate_sentence(line)\n","        result= get_cosine_val (translation, line)\n","        scores.append(result)\n","\n","    df[\"cosine_similarity\"]= scores    ## Cosine score calculated\n","\n","    ####### END Calculate Cosine Similarity for two sentences\n","    \n","\n","    # Candidate Tokens \n","    candidate_tokens=[]\n","\n","\n","    for line in sample_sentences['hindi']:\n","    \n","        result= translate_sentence(line)\n","        temp =result.split()\n","        temp= temp[:-1]\n","        candidate_tokens.append(temp)\n","        \n","\n","    df[\"candidate\"]= candidate_tokens\n","\n","\n","    ## Calculate BLEU score\n","\n","    scores=[]\n","    for reference, candidate in zip(df['reference'], df['candidate']):\n","        list_of_references= [reference]  # we have only one reference sentence for each candidate sentence\n","        result= sentence_bleu(list_of_references, candidate,weights=(1, 0, 0, 0))  ## Check this line\n","        scores.append(result)\n","    \n","    df[\"bleu_score\"]= scores    ## BLEU score calculated\n","\n","    ## Calcualte ROUGE score\n","    scores=[]\n","    for reference, candidate in zip(df['reference'], df['candidate']):\n","        temp =['captain', 'of', 'the', 'delta', 'flight']\n","        references =tf.ragged.constant([reference])\n","        hypotheses= tf.ragged.constant([candidate])\n","\n","        result= text.metrics.rouge_l(hypotheses, references)\n","        \n","        result_str= \" F-measure: \"+str(result.f_measure.numpy()[0]) +\"  Precision: \"+str(result.p_measure.numpy()[0])+\"  Recall: \"+str(result.r_measure.numpy()[0])\n","        column=[\"f_measure\", \"p_measure\", \"r_measure\"]\n","        data= [[result.f_measure.numpy()[0] ,result.p_measure.numpy()[0] , result.r_measure.numpy()[0] ]]\n","        metric= pd.DataFrame(data=data, columns=column)\n","        resultObj= {\"f_measure\": result.f_measure.numpy()[0] , \"p_measure\": result.p_measure.numpy()[0],  \"r_measure\":result.r_measure.numpy()[0] }  \n","        scores.append(resultObj)\n","    \n","    \n","\n","    df[\"rouge_score\"]= scores  ## ROUGE score calculated\n","\n","    # print(\"My table \", df)\n","\n","    rouge_metric= pd.DataFrame.from_records(df['rouge_score'])\n","\n","    average_f_measure = rouge_metric['f_measure'].mean()\n","    average_p_measure = rouge_metric['p_measure'].mean()\n","    average_r_measure = rouge_metric['r_measure'].mean()\n","    average_cosine= df['cosine_similarity'].mean()\n","    average_bleu= df['bleu_score'].mean()\n","\n","    ## return BLEU and ROUGE score to the list \n","    return [average_f_measure, average_p_measure,average_r_measure, average_cosine, average_bleu]\n","\n","        \n","\n","    "],"metadata":{"id":"r9dvKzzc4pdQ","executionInfo":{"status":"ok","timestamp":1666021812954,"user_tz":-360,"elapsed":748,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Get Summary Statistics Table"],"metadata":{"id":"YBiGboDFKJyy"}},{"cell_type":"code","source":["\n","stat=[]\n","for item in model_list:\n","\n","    model_path= path+item+\"/model.h5\" \n","    path_encoder_parameters= path+item+\"/parameters/encoder_parameters.pickle\" \n","    path_encoder_dictionary= path+item+\"/dictionaries/encoder_dictionary.pickle\" \n","    path_decoder_parameters= path+item+\"/parameters/decoder_parameters.pickle\" \n","    path_decoder_dictionary= path+item+\"/dictionaries/decoder_dictionary.pickle\" \n","    encoderPath= path+item+\"/enc_model.h5\" \n","    decoderPath= path+item+\"/dec_model.h5\" \n","    # print(model_path, path_encoder_parameters,path_encoder_dictionary,path_decoder_parameters,path_decoder_dictionary,encoderPath,decoderPath)\n","    result= get_model_statistics_summary(model_path, path_encoder_parameters,path_encoder_dictionary,path_decoder_parameters,path_decoder_dictionary,encoderPath,decoderPath)\n","    result.insert(0, item)\n","    stat.append(result)\n","    print(result)\n","\n","table =pd.DataFrame(columns=[\"Dataset Size\",\"average_f_measure\", \"average_p_measure\",\"average_r_measure\", \"average_cosine\" ,\"average_bleu\"], data=stat)\n","table"],"metadata":{"id":"USuXFNZ5AS_l","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1666021920657,"user_tz":-360,"elapsed":97560,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"b8e02877-4275-468b-f601-0a2478c16207"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 12)]         0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 9)]          0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 12, 256)      309760      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, 9, 256)       236032      ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 9, 256),     525312      ['embedding_1[0][0]',            \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, 9, 922)       236954      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,833,370\n","Trainable params: 1,833,370\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","{'max_encoder_seq_length': 12, 'num_encoder_tokens': 1210}\n","{'max_decoder_seq_length': 9, 'num_decoder_tokens': 922}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:136: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["['1000', 0.046190478, 0.084285714, 0.03206349, 0.05986744914343021, 0.01686658799604492]\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 21)]         0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 20)]         0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 21, 256)      770816      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, 20, 256)      612864      ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 20, 256),    525312      ['embedding_1[0][0]',            \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, 20, 2394)     615258      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 3,049,562\n","Trainable params: 3,049,562\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","{'max_encoder_seq_length': 21, 'num_encoder_tokens': 3011}\n","{'max_decoder_seq_length': 20, 'num_decoder_tokens': 2394}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"]},{"output_type":"stream","name":"stdout","text":["['2908', 0.11854134, 0.15424104, 0.09820272, 0.04791435745790533, 0.09859566598104583]\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 40)]         0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 43)]         0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 40, 256)      279552      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, 43, 256)      205568      ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 43, 256),    525312      ['embedding_1[0][0]',            \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, 43, 803)      206371      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,742,115\n","Trainable params: 1,742,115\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","{'max_encoder_seq_length': 40, 'num_encoder_tokens': 1092}\n","{'max_decoder_seq_length': 43, 'num_decoder_tokens': 803}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:Model was constructed with shape (None, 43) for input KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"]},{"output_type":"stream","name":"stdout","text":["['5000', 0.14846973, 0.15582122, 0.14605662, 0.21918839465828044, 0.14956387693403855]\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 48)]         0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 43)]         0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 48, 256)      521728      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, 43, 256)      399104      ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 43, 256),    525312      ['embedding_1[0][0]',            \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, 43, 1559)     400663      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,372,119\n","Trainable params: 2,372,119\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","{'max_encoder_seq_length': 48, 'num_encoder_tokens': 2038}\n","{'max_decoder_seq_length': 43, 'num_decoder_tokens': 1559}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:Model was constructed with shape (None, 43) for input KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"]},{"output_type":"stream","name":"stdout","text":["['10000', 0.12095173, 0.1367152, 0.110339105, 0.2373418345511648, 0.1053997844055465]\n"]},{"output_type":"execute_result","data":{"text/plain":["  Dataset Size  average_f_measure  average_p_measure  average_r_measure  \\\n","0         1000           0.046190           0.084286           0.032063   \n","1         2908           0.118541           0.154241           0.098203   \n","2         5000           0.148470           0.155821           0.146057   \n","3        10000           0.120952           0.136715           0.110339   \n","\n","   average_cosine  average_bleu  \n","0        0.059867      0.016867  \n","1        0.047914      0.098596  \n","2        0.219188      0.149564  \n","3        0.237342      0.105400  "],"text/html":["\n","  <div id=\"df-712e500b-5c20-4588-a8d4-b6b19d7f4bea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset Size</th>\n","      <th>average_f_measure</th>\n","      <th>average_p_measure</th>\n","      <th>average_r_measure</th>\n","      <th>average_cosine</th>\n","      <th>average_bleu</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000</td>\n","      <td>0.046190</td>\n","      <td>0.084286</td>\n","      <td>0.032063</td>\n","      <td>0.059867</td>\n","      <td>0.016867</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2908</td>\n","      <td>0.118541</td>\n","      <td>0.154241</td>\n","      <td>0.098203</td>\n","      <td>0.047914</td>\n","      <td>0.098596</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5000</td>\n","      <td>0.148470</td>\n","      <td>0.155821</td>\n","      <td>0.146057</td>\n","      <td>0.219188</td>\n","      <td>0.149564</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10000</td>\n","      <td>0.120952</td>\n","      <td>0.136715</td>\n","      <td>0.110339</td>\n","      <td>0.237342</td>\n","      <td>0.105400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-712e500b-5c20-4588-a8d4-b6b19d7f4bea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-712e500b-5c20-4588-a8d4-b6b19d7f4bea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-712e500b-5c20-4588-a8d4-b6b19d7f4bea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["table"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"5xjS602GsIBG","executionInfo":{"status":"ok","timestamp":1666021927676,"user_tz":-360,"elapsed":576,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"8e592816-4baa-404b-d1dc-251a4f8d5d30"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Dataset Size  average_f_measure  average_p_measure  average_r_measure  \\\n","0         1000           0.046190           0.084286           0.032063   \n","1         2908           0.118541           0.154241           0.098203   \n","2         5000           0.148470           0.155821           0.146057   \n","3        10000           0.120952           0.136715           0.110339   \n","\n","   average_cosine  average_bleu  \n","0        0.059867      0.016867  \n","1        0.047914      0.098596  \n","2        0.219188      0.149564  \n","3        0.237342      0.105400  "],"text/html":["\n","  <div id=\"df-5a34821e-23ae-43dc-add2-fc8b70309466\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset Size</th>\n","      <th>average_f_measure</th>\n","      <th>average_p_measure</th>\n","      <th>average_r_measure</th>\n","      <th>average_cosine</th>\n","      <th>average_bleu</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000</td>\n","      <td>0.046190</td>\n","      <td>0.084286</td>\n","      <td>0.032063</td>\n","      <td>0.059867</td>\n","      <td>0.016867</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2908</td>\n","      <td>0.118541</td>\n","      <td>0.154241</td>\n","      <td>0.098203</td>\n","      <td>0.047914</td>\n","      <td>0.098596</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5000</td>\n","      <td>0.148470</td>\n","      <td>0.155821</td>\n","      <td>0.146057</td>\n","      <td>0.219188</td>\n","      <td>0.149564</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10000</td>\n","      <td>0.120952</td>\n","      <td>0.136715</td>\n","      <td>0.110339</td>\n","      <td>0.237342</td>\n","      <td>0.105400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a34821e-23ae-43dc-add2-fc8b70309466')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5a34821e-23ae-43dc-add2-fc8b70309466 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5a34821e-23ae-43dc-add2-fc8b70309466');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["#Visualizations"],"metadata":{"id":"70wi_tlCG4Mn"}},{"cell_type":"code","source":["import matplotlib.pyplot as plot\n","from matplotlib.ticker import ScalarFormatter\n","#,figsize=(10,15)\n","table.plot.bar(x=\"Dataset Size\",figsize=(15,10))\n","plot.show(block=True);"],"metadata":{"id":"xtykWgaEGRNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["table.plot.bar(x=\"Dataset Size\",y=\"average_bleu\")\n","plot.yscale(\"log\")\n","plot.gca().yaxis.set_major_formatter(ScalarFormatter())\n","\n","plot.show(block=True);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301},"id":"AKB9tf1sIYpN","executionInfo":{"status":"ok","timestamp":1666021952500,"user_tz":-360,"elapsed":914,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"8250dd5f-eeb6-455e-cd7e-5b9b547f713e"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyMvVdrnjD4+uHPpukleEdtz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}