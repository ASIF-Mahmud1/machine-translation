{"cells":[{"cell_type":"markdown","metadata":{"id":"B453NNRC0joS"},"source":["# Load Model From Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44100,"status":"ok","timestamp":1665908691730,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"},"user_tz":-360},"id":"jvdaYoDtgQMT","outputId":"aae5913d-4f1c-4c6f-9904-3437a3254683"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Initialize Paths of Models and Parameters"],"metadata":{"id":"5zoz2cQPKZtf"}},{"cell_type":"code","source":["path= \"/content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/\"\n","\n","model_list=[\"1000\",\"2908\",\"5000\",\"10000\"]"],"metadata":{"id":"MFKnZu9fKhqQ","executionInfo":{"status":"ok","timestamp":1665908691731,"user_tz":-360,"elapsed":6,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Install and Import Modules"],"metadata":{"id":"fLGZBCvrJC6X"}},{"cell_type":"code","source":["!pip install -q \"tensorflow==2.8.*\"\n","!pip install -q \"tensorflow-text==2.8.*\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maOThzQQ43jO","executionInfo":{"status":"ok","timestamp":1665908777060,"user_tz":-360,"elapsed":85333,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"f2906fa3-82ef-429c-a6f4-89ed26538d23"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 497.9 MB 33 kB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 46.8 MB/s \n","\u001b[K     |████████████████████████████████| 462 kB 64.2 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 49.6 MB/s \n","\u001b[K     |████████████████████████████████| 4.9 MB 4.3 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"_Fo-82DfGVBw","executionInfo":{"status":"ok","timestamp":1665908781369,"user_tz":-360,"elapsed":4314,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.utils.vis_utils import plot_model\n","import pickle\n","from tensorflow.keras.layers import Input, Embedding,Dense,  LSTM\n","from tensorflow.keras import layers , activations , models , preprocessing , utils\n","from tensorflow.keras.models import load_model\n","import numpy as np\n","from nltk.translate.bleu_score import sentence_bleu\n","import pandas as pd\n","import tensorflow_text as text"]},{"cell_type":"code","source":["!pip install fasttext\n","import fasttext.util"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"snEbCRU_q38p","executionInfo":{"status":"ok","timestamp":1665908844436,"user_tz":-360,"elapsed":63075,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"ebb9bc9d-dea6-4ce0-e2bf-c4e738e6ae61"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fasttext\n","  Downloading fasttext-0.9.2.tar.gz (68 kB)\n","\u001b[K     |████████████████████████████████| 68 kB 2.2 MB/s \n","\u001b[?25hCollecting pybind11>=2.2\n","  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3166311 sha256=07a3e1a2d3cc20568c2ef05680c97b57fc7684c957de24c6fc290efede019d83\n","  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n","Successfully built fasttext\n","Installing collected packages: pybind11, fasttext\n","Successfully installed fasttext-0.9.2 pybind11-2.10.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"PDoZgXN3uQJn"},"source":["# Download Sentences for Test"]},{"cell_type":"code","source":["!wget http://www.manythings.org/anki/hin-eng.zip -O hin-eng.zip\n","!unzip hin-eng.zip"],"metadata":{"id":"O8PEeQ4LY6Xg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665908845944,"user_tz":-360,"elapsed":1536,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"de7db2ed-0bee-484d-9a78-8f9cb3664af5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-16 08:27:24--  http://www.manythings.org/anki/hin-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n","Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 131711 (129K) [application/zip]\n","Saving to: ‘hin-eng.zip’\n","\n","hin-eng.zip         100%[===================>] 128.62K   267KB/s    in 0.5s    \n","\n","2022-10-16 08:27:25 (267 KB/s) - ‘hin-eng.zip’ saved [131711/131711]\n","\n","Archive:  hin-eng.zip\n","  inflating: hin.txt                 \n","  inflating: _about.txt              \n"]}]},{"cell_type":"markdown","source":["# Def. Get Summary Statistics for every model "],"metadata":{"id":"sAM8mvxHJPj3"}},{"cell_type":"code","source":["def get_model_statistics_summary(model_path,path_encoder_parameters,path_encoder_dictionary,path_decoder_parameters,path_decoder_dictionary, encoderPath, decoderPath ):\n","\n"," \n","    reconstructed_model = keras.models.load_model(model_path)\n","    plot_model(reconstructed_model, to_file='modelsummary.png', show_shapes=True, show_layer_names=True)\n","    reconstructed_model.summary()\n","\n","\n","    ## Load Dictionaries and Parameters \n","    path_encoder_parameters= path_encoder_parameters\n","    path_encoder_dictionary= path_encoder_dictionary\n","    path_decoder_parameters= path_decoder_parameters\n","    path_decoder_dictionary= path_decoder_dictionary\n","\n","    # loading\n","    with open(path_encoder_parameters, 'rb') as handle:\n","        encoder_parameters = pickle.load(handle)\n","\n","    # loading\n","    with open(path_encoder_dictionary, 'rb') as handle:\n","        encoder_dictionary = pickle.load(handle)\n","\n","    # loading\n","    with open(path_decoder_parameters, 'rb') as handle:\n","        decoder_parameters= pickle.load(handle)\n","\n","    # loading\n","    with open(path_decoder_dictionary, 'rb') as handle:\n","        decoder_dictionary = pickle.load(handle)    \n","\n","    print(encoder_parameters)\n","    # encoder_dictionary\n","    print(decoder_parameters)\n","    # decoder_dictionary\n","\n","    encoder_inputs = reconstructed_model.input[0]  # input_1\n","    encoder_outputs, state_h_enc, state_c_enc = reconstructed_model.layers[4].output  # lstm_1\n","    encoder_states = [state_h_enc, state_c_enc]\n","    encoder_model = keras.Model(encoder_inputs, encoder_states)\n","    latent_dim = 256  # Note: may be need to save in drive as well\n","\n","\n","    num_decoder_tokens =decoder_parameters['num_decoder_tokens']\n","    max_output_length= decoder_parameters['max_decoder_seq_length']\n","    max_input_length= encoder_parameters['max_encoder_seq_length']\n","\n","    encoder_word_dict=encoder_dictionary\n","    decoder_word_dict= decoder_dictionary\n","\n","\n","    decoder_inputs = Input(shape=( max_output_length , ))\n","    decoder_embedding = Embedding( num_decoder_tokens, 256 , mask_zero=True) (decoder_inputs)\n","\n","    decoder_lstm = LSTM( 256 , return_state=True , return_sequences=True , recurrent_dropout=0.2 , dropout=0.2)\n","    decoder_dense = Dense( num_decoder_tokens , activation=tf.keras.activations.softmax ) \n","\n","\n","    def str_to_tokens( sentence : str ):\n","        words = sentence.lower().split()\n","        tokens_list = list()\n","        for word in words:\n","                # print(\"word \", word, eng_word_dict.get(word,1) )\n","                my_word=  encoder_word_dict.get(word,1)\n","                tokens_list.append(my_word) \n","    \n","        return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_input_length , padding='post')\n","\n","\n","    def make_inference_models():\n","        \n","            encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n","            \n","            decoder_state_input_h = tf.keras.layers.Input(shape=( 256,))\n","            decoder_state_input_c = tf.keras.layers.Input(shape=( 256 ,))\n","            \n","            decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","            \n","            decoder_outputs, state_h, state_c = decoder_lstm(\n","                decoder_embedding , initial_state=decoder_states_inputs)\n","            decoder_states = [state_h, state_c]\n","            decoder_outputs = decoder_dense(decoder_outputs)\n","            decoder_model = tf.keras.models.Model(\n","                [decoder_inputs] + decoder_states_inputs,\n","                [decoder_outputs] + decoder_states)\n","            \n","            return encoder_model , decoder_model\n","\n","\n","    enc_model , dec_model = make_inference_models()\n","\n","\n","    # Test Previous Model\n","\n","\n","    encoderPath= encoderPath\n","    decoderPath= decoderPath\n","\n","    # loading\n","\n","    enc_model =  load_model(encoderPath)\n","    dec_model  =  load_model(decoderPath)\n","\n","    def translate_sentence(sentence):\n","        for epoch in range(1 ):\n","            states_values = enc_model.predict( str_to_tokens(sentence ) )\n","            empty_target_seq = np.zeros( ( 1 , 1 ) )\n","            empty_target_seq[0, 0] = decoder_word_dict['start']\n","            stop_condition = False\n","            decoded_translation = ''\n","            while not stop_condition :\n","                dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n","                sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n","                sampled_word = None\n","                for word , index in decoder_word_dict.items() :\n","                    if sampled_word_index == index :\n","                        decoded_translation += ' {}'.format( word )\n","                        sampled_word = word\n","                \n","                if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n","                    stop_condition = True\n","                    \n","                empty_target_seq = np.zeros( ( 1 , 1 ) )  \n","                empty_target_seq[ 0 , 0 ] = sampled_word_index\n","                states_values = [ h , c ] \n","\n","            print(\"Decoded Traslation \", decoded_translation )\n","        return  decoded_translation\n","\n","\n","    ## Get sentences to test the model\n","\n","    lines = pd.read_table( 'hin.txt' , names=[ 'eng' , 'hindi' ] )\n","    lines.reset_index( level=0 , inplace=True )\n","    lines.rename( columns={ 'index' : 'eng' , 'eng' : 'hindi' , 'hindi' : 'c' } , inplace=True )\n","    lines = lines.drop( 'c' , 1 )  \n","\n","    sample_sentences= lines[-10:]\n","    sample_sentences\n","\n","    # Reference Token \n","\n","    reference_tokens=[]\n","\n","    for line in sample_sentences['eng']:\n","        # print( line.split() ) \n","        reference_tokens.append( line.split() )\n","\n","    df = pd.DataFrame(      columns=['reference', 'candidate', 'bleu_score'],  )\n","\n","    df[\"reference\"]= reference_tokens\n","\n","\n","\n","    # Candidate Tokens \n","    candidate_tokens=[]\n","\n","\n","    for line in sample_sentences['hindi']:\n","    \n","        result= translate_sentence(line)\n","        temp =result.split()\n","        temp= temp[:-1]\n","        candidate_tokens.append(temp)\n","        \n","\n","    df[\"candidate\"]= candidate_tokens\n","\n","\n","    ## Calculate BLEU score\n","\n","    scores=[]\n","    for reference, candidate in zip(df['reference'], df['candidate']):\n","    \n","        result= sentence_bleu([reference], candidate)\n","        scores.append(result)\n","    \n","    df[\"bleu_score\"]= scores    ## BLEU score calculated\n","\n","\n","    ## Calcualte ROUGE score\n","    scores=[]\n","    for reference, candidate in zip(df['reference'], df['candidate']):\n","        temp =['captain', 'of', 'the', 'delta', 'flight']\n","        references =tf.ragged.constant([reference])\n","        hypotheses= tf.ragged.constant([candidate])\n","\n","        result= text.metrics.rouge_l(hypotheses, references)\n","        \n","        result_str= \" F-measure: \"+str(result.f_measure.numpy()[0]) +\"  Precision: \"+str(result.p_measure.numpy()[0])+\"  Recall: \"+str(result.r_measure.numpy()[0])\n","        column=[\"f_measure\", \"p_measure\", \"r_measure\"]\n","        data= [[result.f_measure.numpy()[0] ,result.p_measure.numpy()[0] , result.r_measure.numpy()[0] ]]\n","        metric= pd.DataFrame(data=data, columns=column)\n","        resultObj= {\"f_measure\": result.f_measure.numpy()[0] , \"p_measure\": result.p_measure.numpy()[0],  \"r_measure\":result.r_measure.numpy()[0] }  \n","        scores.append(resultObj)\n","    \n","    \n","\n","    df[\"rouge_score\"]= scores  ## ROUGE score calculated\n","\n","    print(\"My table \", df)\n","\n","    rouge_metric= pd.DataFrame.from_records(df['rouge_score'])\n","\n","    average_f_measure = rouge_metric['f_measure'].mean()\n","    average_p_measure = rouge_metric['p_measure'].mean()\n","    average_r_measure = rouge_metric['r_measure'].mean()\n","    # average_cosine= df['cosine_similarity'].mean()\n","    average_bleu= df['bleu_score'].mean()\n","\n","    ## return BLEU and ROUGE score to the list \n","    return [average_f_measure, average_p_measure,average_r_measure, average_bleu]\n","\n","        \n","\n","    "],"metadata":{"id":"r9dvKzzc4pdQ","executionInfo":{"status":"ok","timestamp":1665908845945,"user_tz":-360,"elapsed":8,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Get Summary Statistics Table"],"metadata":{"id":"YBiGboDFKJyy"}},{"cell_type":"code","source":["\n","stat=[]\n","for item in model_list:\n","\n","    model_path= path+item+\"/model.h5\" \n","    path_encoder_parameters= path+item+\"/parameters/encoder_parameters.pickle\" \n","    path_encoder_dictionary= path+item+\"/dictionaries/encoder_dictionary.pickle\" \n","    path_decoder_parameters= path+item+\"/parameters/decoder_parameters.pickle\" \n","    path_decoder_dictionary= path+item+\"/dictionaries/decoder_dictionary.pickle\" \n","    encoderPath= path+item+\"/enc_model.h5\" \n","    decoderPath= path+item+\"/dec_model.h5\" \n","    print(model_path, path_encoder_parameters,path_encoder_dictionary,path_decoder_parameters,path_decoder_dictionary,encoderPath,decoderPath)\n","    result= get_model_statistics_summary(model_path, path_encoder_parameters,path_encoder_dictionary,path_decoder_parameters,path_decoder_dictionary,encoderPath,decoderPath)\n","    result.insert(0, item)\n","    stat.append(result)\n","    print(result)\n","\n","table =pd.DataFrame(columns=[\"Dataset Size\",\"average_f_measure\", \"average_p_measure\",\"average_r_measure\",  \"average_bleu\"], data=stat)\n","table"],"metadata":{"id":"USuXFNZ5AS_l","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1665908930656,"user_tz":-360,"elapsed":84718,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"b6b5e58d-5bd1-4d0e-fed7-bcf8ca65b3fd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/1000/model.h5 /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/1000/parameters/encoder_parameters.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/1000/dictionaries/encoder_dictionary.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/1000/parameters/decoder_parameters.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/1000/dictionaries/decoder_dictionary.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/1000/enc_model.h5 /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/1000/dec_model.h5\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 12)]         0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 9)]          0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 12, 256)      309760      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, 9, 256)       236032      ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 9, 256),     525312      ['embedding_1[0][0]',            \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, 9, 922)       236954      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,833,370\n","Trainable params: 1,833,370\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","{'max_encoder_seq_length': 12, 'num_encoder_tokens': 1210}\n","{'max_decoder_seq_length': 9, 'num_decoder_tokens': 922}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:135: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"]},{"output_type":"stream","name":"stdout","text":["Decoded Traslation   she isn't my cousin end\n","Decoded Traslation   she is my wealthy woman end\n","Decoded Traslation   my family loved my woman end\n","Decoded Traslation   she is his man but the job end\n","Decoded Traslation   that guy annoys me end\n","Decoded Traslation   he is not my little toy end\n","Decoded Traslation   she is poor but the sharp end\n","Decoded Traslation   she isn't my cousin end\n","Decoded Traslation   he tends to be very beer end\n","Decoded Traslation   she isn't my cousin end\n","My table                                             reference  \\\n","0  [Mother, Teresa, was, a, Catholic, nun, who, l...   \n","1  [George, Washington, was, the, first, presiden...   \n","2  [From, my, point, of, view,, Australia, is, on...   \n","3  [In, 1951,, Sister, Teresa, was, sent, to, Cal...   \n","4  [Mother, Teresa, used, the, prize, money, for,...   \n","5  [If, you, go, to, that, supermarket,, you, can...   \n","6  [The, passengers, who, were, injured, in, the,...   \n","7  [Democracy, is, the, worst, form, of, governme...   \n","8  [If, my, boy, had, not, been, killed, in, the,...   \n","9  [When, I, was, a, kid,, touching, bugs, didn't...   \n","\n","                            candidate     bleu_score  \\\n","0            [she, isn't, my, cousin]   0.000000e+00   \n","1       [she, is, my, wealthy, woman]   0.000000e+00   \n","2      [my, family, loved, my, woman]  1.648834e-232   \n","3  [she, is, his, man, but, the, job]  4.120400e-232   \n","4             [that, guy, annoys, me]   0.000000e+00   \n","5      [he, is, not, my, little, toy]   0.000000e+00   \n","6    [she, is, poor, but, the, sharp]  3.068395e-232   \n","7            [she, isn't, my, cousin]   0.000000e+00   \n","8     [he, tends, to, be, very, beer]  1.873437e-232   \n","9            [she, isn't, my, cousin]   0.000000e+00   \n","\n","                                         rouge_score  \n","0  {'f_measure': 0.0, 'p_measure': 0.0, 'r_measur...  \n","1  {'f_measure': 0.0, 'p_measure': 0.0, 'r_measur...  \n","2  {'f_measure': 0.1, 'p_measure': 0.2, 'r_measur...  \n","3  {'f_measure': 0.0952381, 'p_measure': 0.142857...  \n","4  {'f_measure': 0.0, 'p_measure': 0.0, 'r_measur...  \n","5  {'f_measure': 0.0, 'p_measure': 0.0, 'r_measur...  \n","6  {'f_measure': 0.1, 'p_measure': 0.16666667, 'r...  \n","7  {'f_measure': 0.0, 'p_measure': 0.0, 'r_measur...  \n","8  {'f_measure': 0.16666667, 'p_measure': 0.33333...  \n","9  {'f_measure': 0.0, 'p_measure': 0.0, 'r_measur...  \n","['1000', 0.046190478, 0.084285714, 0.03206349, 1.071106460849533e-232]\n","/content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/2908/model.h5 /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/2908/parameters/encoder_parameters.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/2908/dictionaries/encoder_dictionary.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/2908/parameters/decoder_parameters.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/2908/dictionaries/decoder_dictionary.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/2908/enc_model.h5 /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/2908/dec_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 21)]         0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 20)]         0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 21, 256)      770816      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, 20, 256)      612864      ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 20, 256),    525312      ['embedding_1[0][0]',            \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, 20, 2394)     615258      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 3,049,562\n","Trainable params: 3,049,562\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","{'max_encoder_seq_length': 21, 'num_encoder_tokens': 3011}\n","{'max_decoder_seq_length': 20, 'num_decoder_tokens': 2394}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:135: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"]},{"output_type":"stream","name":"stdout","text":["Decoded Traslation   a man was thrown for a long were wrong end\n","Decoded Traslation   could you a doctor in end\n","Decoded Traslation   my father has just cleared the room of the table end\n","Decoded Traslation   the man woke up for a strange man end\n","Decoded Traslation   whoever wins the rule to the rumor say that we have a house end\n","Decoded Traslation   it was not to do that he went to the job end\n","Decoded Traslation   did the police arrest his job end\n","Decoded Traslation   the doctor advised that he went to the job to the party end\n","Decoded Traslation   my father is afraid of her grandmother end\n","Decoded Traslation   i don't think if i had a fight with my mother time end\n","My table                                             reference  \\\n","0  [Mother, Teresa, was, a, Catholic, nun, who, l...   \n","1  [George, Washington, was, the, first, presiden...   \n","2  [From, my, point, of, view,, Australia, is, on...   \n","3  [In, 1951,, Sister, Teresa, was, sent, to, Cal...   \n","4  [Mother, Teresa, used, the, prize, money, for,...   \n","5  [If, you, go, to, that, supermarket,, you, can...   \n","6  [The, passengers, who, were, injured, in, the,...   \n","7  [Democracy, is, the, worst, form, of, governme...   \n","8  [If, my, boy, had, not, been, killed, in, the,...   \n","9  [When, I, was, a, kid,, touching, bugs, didn't...   \n","\n","                                           candidate     bleu_score  \\\n","0   [a, man, was, thrown, for, a, long, were, wrong]  8.020204e-232   \n","1                        [could, you, a, doctor, in]   0.000000e+00   \n","2  [my, father, has, just, cleared, the, room, of...  4.154123e-155   \n","3         [the, man, woke, up, for, a, strange, man]  5.116995e-232   \n","4  [whoever, wins, the, rule, to, the, rumor, say...  9.782851e-232   \n","5  [it, was, not, to, do, that, he, went, to, the...  6.894928e-232   \n","6               [did, the, police, arrest, his, job]  3.068395e-232   \n","7  [the, doctor, advised, that, he, went, to, the...  1.003274e-231   \n","8     [my, father, is, afraid, of, her, grandmother]  2.326864e-232   \n","9  [i, don't, think, if, i, had, a, fight, with, ...  4.254034e-232   \n","\n","                                         rouge_score  \n","0  {'f_measure': 0.18181819, 'p_measure': 0.22222...  \n","1  {'f_measure': 0.0, 'p_measure': 0.0, 'r_measur...  \n","2  {'f_measure': 0.24000001, 'p_measure': 0.3, 'r...  \n","3  {'f_measure': 0.09090909, 'p_measure': 0.125, ...  \n","4  {'f_measure': 0.14285715, 'p_measure': 0.15384...  \n","5  {'f_measure': 0.14285715, 'p_measure': 0.18181...  \n","6  {'f_measure': 0.1, 'p_measure': 0.16666667, 'r...  \n","7  {'f_measure': 0.14814816, 'p_measure': 0.16666...  \n","8  {'f_measure': 0.080000006, 'p_measure': 0.1428...  \n","9  {'f_measure': 0.058823533, 'p_measure': 0.0833...  \n","['2908', 0.11854134, 0.15424104, 0.09820272, 4.154122940232254e-156]\n","/content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/5000/model.h5 /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/5000/parameters/encoder_parameters.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/5000/dictionaries/encoder_dictionary.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/5000/parameters/decoder_parameters.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/5000/dictionaries/decoder_dictionary.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/5000/enc_model.h5 /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/5000/dec_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 40)]         0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 43)]         0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 40, 256)      279552      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, 43, 256)      205568      ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 43, 256),    525312      ['embedding_1[0][0]',            \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, 43, 803)      206371      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,742,115\n","Trainable params: 1,742,115\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","{'max_encoder_seq_length': 40, 'num_encoder_tokens': 1092}\n","{'max_decoder_seq_length': 43, 'num_decoder_tokens': 803}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:135: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","WARNING:tensorflow:Model was constructed with shape (None, 43) for input KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"]},{"output_type":"stream","name":"stdout","text":["Decoded Traslation   move a onto the ace of hearts next to the ace of hearts end\n","Decoded Traslation   the four of hearts next to the four of hearts end\n","Decoded Traslation   move a onto the ace of hearts next to the seven of hearts end\n","Decoded Traslation   the ace of hearts next to the seven of hearts next to the ace of hearts end\n","Decoded Traslation   place the color and opacity of the highlight box when selecting of merchantability or fitness for a particular purpose see the gnu general public end\n","Decoded Traslation   the color and opacity of the highlight box when selecting of diamonds next to the free software foundation end\n","Decoded Traslation   the ace of hearts next to the ace of hearts end\n","Decoded Traslation   the ace of hearts next to the ace of hearts next to the ace of hearts end\n","Decoded Traslation   place the six of hearts next to the five of hearts end\n","Decoded Traslation   the list of plugins that are disabled by the five of the gnu general public license along with this program if not see end\n","My table                                             reference  \\\n","0  [Mother, Teresa, was, a, Catholic, nun, who, l...   \n","1  [George, Washington, was, the, first, presiden...   \n","2  [From, my, point, of, view,, Australia, is, on...   \n","3  [In, 1951,, Sister, Teresa, was, sent, to, Cal...   \n","4  [Mother, Teresa, used, the, prize, money, for,...   \n","5  [If, you, go, to, that, supermarket,, you, can...   \n","6  [The, passengers, who, were, injured, in, the,...   \n","7  [Democracy, is, the, worst, form, of, governme...   \n","8  [If, my, boy, had, not, been, killed, in, the,...   \n","9  [When, I, was, a, kid,, touching, bugs, didn't...   \n","\n","                                           candidate     bleu_score  \\\n","0  [move, a, onto, the, ace, of, hearts, next, to...  9.594503e-232   \n","1  [the, four, of, hearts, next, to, the, four, o...  1.186218e-231   \n","2  [move, a, onto, the, ace, of, hearts, next, to...  1.163384e-231   \n","3  [the, ace, of, hearts, next, to, the, seven, o...  1.083268e-231   \n","4  [place, the, color, and, opacity, of, the, hig...  1.164047e-231   \n","5  [the, color, and, opacity, of, the, highlight,...  8.844844e-232   \n","6  [the, ace, of, hearts, next, to, the, ace, of,...  4.272422e-155   \n","7  [the, ace, of, hearts, next, to, the, ace, of,...  1.198833e-231   \n","8  [place, the, six, of, hearts, next, to, the, f...  5.294085e-232   \n","9  [the, list, of, plugins, that, are, disabled, ...  8.319100e-232   \n","\n","                                         rouge_score  \n","0  {'f_measure': 0.07692308, 'p_measure': 0.07692...  \n","1  {'f_measure': 0.36363637, 'p_measure': 0.4, 'r...  \n","2  {'f_measure': 0.14285715, 'p_measure': 0.15384...  \n","3  {'f_measure': 0.13333334, 'p_measure': 0.125, ...  \n","4  {'f_measure': 0.15384616, 'p_measure': 0.125, ...  \n","5  {'f_measure': 0.057142857, 'p_measure': 0.0555...  \n","6  {'f_measure': 0.25, 'p_measure': 0.3, 'r_measu...  \n","7  {'f_measure': 0.1935484, 'p_measure': 0.1875, ...  \n","8  {'f_measure': 0.06896552, 'p_measure': 0.09090...  \n","9  {'f_measure': 0.04444444, 'p_measure': 0.04347...  \n","['5000', 0.14846973, 0.15582122, 0.14605662, 4.27242167093289e-156]\n","/content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/10000/model.h5 /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/10000/parameters/encoder_parameters.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/10000/dictionaries/encoder_dictionary.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/10000/parameters/decoder_parameters.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/10000/dictionaries/decoder_dictionary.pickle /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/10000/enc_model.h5 /content/drive/My Drive/Machine Learning/GitHub Projects/machine-translation/models/10000/dec_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 48)]         0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 43)]         0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 48, 256)      521728      ['input_1[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, 43, 256)      399104      ['input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 43, 256),    525312      ['embedding_1[0][0]',            \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, 43, 1559)     400663      ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,372,119\n","Trainable params: 2,372,119\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","{'max_encoder_seq_length': 48, 'num_encoder_tokens': 2038}\n","{'max_decoder_seq_length': 43, 'num_decoder_tokens': 1559}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:135: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","WARNING:tensorflow:Model was constructed with shape (None, 43) for input KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"]},{"output_type":"stream","name":"stdout","text":["Decoded Traslation   the help for the four of diamonds next to the document end\n","Decoded Traslation   the help for the current line of the document end\n","Decoded Traslation   add the search and cards from the deck end\n","Decoded Traslation   the new bsd license see the copying and notice played the current layout end\n","Decoded Traslation   enter the selected based the selected text from the selected text to the clipboard end\n","Decoded Traslation   the name of the new bsd license see the current accessible of the current layout end\n","Decoded Traslation   move a onto the four of diamonds next to the four of diamonds end\n","Decoded Traslation   the four of the terms of the current layout for the current block end\n","Decoded Traslation   the search and search and attached version of the current buffer do you want to play end\n","Decoded Traslation   the name of the new card engine that allows many different played the current game you want to the default game klondike is being started end\n","My table                                             reference  \\\n","0  [Mother, Teresa, was, a, Catholic, nun, who, l...   \n","1  [George, Washington, was, the, first, presiden...   \n","2  [From, my, point, of, view,, Australia, is, on...   \n","3  [In, 1951,, Sister, Teresa, was, sent, to, Cal...   \n","4  [Mother, Teresa, used, the, prize, money, for,...   \n","5  [If, you, go, to, that, supermarket,, you, can...   \n","6  [The, passengers, who, were, injured, in, the,...   \n","7  [Democracy, is, the, worst, form, of, governme...   \n","8  [If, my, boy, had, not, been, killed, in, the,...   \n","9  [When, I, was, a, kid,, touching, bugs, didn't...   \n","\n","                                           candidate     bleu_score  \\\n","0  [the, help, for, the, four, of, diamonds, next...   0.000000e+00   \n","1  [the, help, for, the, current, line, of, the, ...  4.828971e-155   \n","2    [add, the, search, and, cards, from, the, deck]  5.370141e-232   \n","3  [the, new, bsd, license, see, the, copying, an...  8.884136e-232   \n","4  [enter, the, selected, based, the, selected, t...  1.042828e-231   \n","5  [the, name, of, the, new, bsd, license, see, t...   0.000000e+00   \n","6  [move, a, onto, the, four, of, diamonds, next,...  5.143564e-155   \n","7  [the, four, of, the, terms, of, the, current, ...  1.082650e-231   \n","8  [the, search, and, search, and, attached, vers...  8.038805e-232   \n","9  [the, name, of, the, new, card, engine, that, ...  8.147480e-232   \n","\n","                                         rouge_score  \n","0  {'f_measure': 0.0, 'p_measure': 0.0, 'r_measur...  \n","1  {'f_measure': 0.28571427, 'p_measure': 0.33333...  \n","2  {'f_measure': 0.17391306, 'p_measure': 0.25, '...  \n","3  {'f_measure': 0.07407408, 'p_measure': 0.07692...  \n","4  {'f_measure': 0.13793105, 'p_measure': 0.14285...  \n","5  {'f_measure': 0.0, 'p_measure': 0.0, 'r_measur...  \n","6  {'f_measure': 0.22222222, 'p_measure': 0.23076...  \n","7  {'f_measure': 0.21428572, 'p_measure': 0.23076...  \n","8  {'f_measure': 0.058823533, 'p_measure': 0.0625...  \n","9  {'f_measure': 0.04255319, 'p_measure': 0.04, '...  \n","['10000', 0.12095173, 0.1367152, 0.110339105, 9.972534358242894e-156]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"execute_result","data":{"text/plain":["  Dataset Size  average_f_measure  average_p_measure  average_r_measure  \\\n","0         1000           0.046190           0.084286           0.032063   \n","1         2908           0.118541           0.154241           0.098203   \n","2         5000           0.148470           0.155821           0.146057   \n","3        10000           0.120952           0.136715           0.110339   \n","\n","    average_bleu  \n","0  1.071106e-232  \n","1  4.154123e-156  \n","2  4.272422e-156  \n","3  9.972534e-156  "],"text/html":["\n","  <div id=\"df-37163cf6-dccf-4f06-bac2-742982440b66\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset Size</th>\n","      <th>average_f_measure</th>\n","      <th>average_p_measure</th>\n","      <th>average_r_measure</th>\n","      <th>average_bleu</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000</td>\n","      <td>0.046190</td>\n","      <td>0.084286</td>\n","      <td>0.032063</td>\n","      <td>1.071106e-232</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2908</td>\n","      <td>0.118541</td>\n","      <td>0.154241</td>\n","      <td>0.098203</td>\n","      <td>4.154123e-156</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5000</td>\n","      <td>0.148470</td>\n","      <td>0.155821</td>\n","      <td>0.146057</td>\n","      <td>4.272422e-156</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10000</td>\n","      <td>0.120952</td>\n","      <td>0.136715</td>\n","      <td>0.110339</td>\n","      <td>9.972534e-156</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37163cf6-dccf-4f06-bac2-742982440b66')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-37163cf6-dccf-4f06-bac2-742982440b66 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-37163cf6-dccf-4f06-bac2-742982440b66');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["table"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"5xjS602GsIBG","executionInfo":{"status":"ok","timestamp":1665908930656,"user_tz":-360,"elapsed":10,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"6a8bbb77-d755-47c6-d07e-b8791fb1fbfd"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Dataset Size  average_f_measure  average_p_measure  average_r_measure  \\\n","0         1000           0.046190           0.084286           0.032063   \n","1         2908           0.118541           0.154241           0.098203   \n","2         5000           0.148470           0.155821           0.146057   \n","3        10000           0.120952           0.136715           0.110339   \n","\n","    average_bleu  \n","0  1.071106e-232  \n","1  4.154123e-156  \n","2  4.272422e-156  \n","3  9.972534e-156  "],"text/html":["\n","  <div id=\"df-e18413c7-41c5-4690-8dd9-257016b9edcd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset Size</th>\n","      <th>average_f_measure</th>\n","      <th>average_p_measure</th>\n","      <th>average_r_measure</th>\n","      <th>average_bleu</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000</td>\n","      <td>0.046190</td>\n","      <td>0.084286</td>\n","      <td>0.032063</td>\n","      <td>1.071106e-232</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2908</td>\n","      <td>0.118541</td>\n","      <td>0.154241</td>\n","      <td>0.098203</td>\n","      <td>4.154123e-156</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5000</td>\n","      <td>0.148470</td>\n","      <td>0.155821</td>\n","      <td>0.146057</td>\n","      <td>4.272422e-156</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10000</td>\n","      <td>0.120952</td>\n","      <td>0.136715</td>\n","      <td>0.110339</td>\n","      <td>9.972534e-156</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e18413c7-41c5-4690-8dd9-257016b9edcd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e18413c7-41c5-4690-8dd9-257016b9edcd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e18413c7-41c5-4690-8dd9-257016b9edcd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["#Visualizations"],"metadata":{"id":"70wi_tlCG4Mn"}},{"cell_type":"code","source":["\n","\n","import matplotlib.pyplot as plot\n","from matplotlib.ticker import ScalarFormatter\n","#,figsize=(10,15)\n","table.plot.bar(x=\"Dataset Size\")\n","plot.show(block=True);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301},"id":"xtykWgaEGRNm","executionInfo":{"status":"ok","timestamp":1665908931466,"user_tz":-360,"elapsed":819,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"eb26ec89-ef44-4f17-f174-33064c522d30"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["table.plot.bar(x=\"Dataset Size\",y=\"average_bleu\")\n","plot.yscale(\"log\")\n","plot.gca().yaxis.set_major_formatter(ScalarFormatter())\n","\n","plot.show(block=True);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"AKB9tf1sIYpN","executionInfo":{"status":"ok","timestamp":1665908931467,"user_tz":-360,"elapsed":14,"user":{"displayName":"'ASIFMAHMUD' IUB","userId":"12339450445858385211"}},"outputId":"7b80f5ef-b2f5-4ea9-dbbe-b33432877372"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyPuXK1H0swNxEX8agoooGAB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}