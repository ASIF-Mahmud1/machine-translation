{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '../../models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list= [\"1000\",\"2908\",\"5000\",\"10000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLGZBCvrJC6X"
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3780,
     "status": "ok",
     "timestamp": 1666197923643,
     "user": {
      "displayName": "'ASIFMAHMUD' IUB",
      "userId": "12339450445858385211"
     },
     "user_tz": -360
    },
    "id": "_Fo-82DfGVBw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pickle\n",
    "from tensorflow.keras.layers import Input, Embedding,Dense,  LSTM\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import pandas as pd\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.device('/physical_device:CPU:0')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.path)\n",
    "directory_path = os.path.abspath(os.path.join('../helper'))\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "\n",
    "translation_path=os.path.abspath(os.path.join('../../utils')) \n",
    "sys.path.append(translation_path)\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1666197923643,
     "user": {
      "displayName": "'ASIFMAHMUD' IUB",
      "userId": "12339450445858385211"
     },
     "user_tz": -360
    },
    "id": "xKbFPJRpobr_"
   },
   "outputs": [],
   "source": [
    "from scoreTest import get_cosine_val, get_BLEU_score, get_ROUGE_score\n",
    "from translate import  translate_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDoZgXN3uQJn"
   },
   "source": [
    "# Download Sentences for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"cfilt/iitb-english-hindi\")\n",
    "\n",
    "pairs=[] \n",
    "for translation_pair in dataset[\"train\"][\"translation\"]:\n",
    "  source_sentence = translation_pair[\"hi\"]\n",
    "  target_sentence = translation_pair[\"en\"]\n",
    "  pairs.append([source_sentence, target_sentence])\n",
    "\n",
    "\n",
    "lines= pd.DataFrame(columns=[ \"hindi\",\"eng\"], data=pairs)\n",
    "lines= lines[:5]\n",
    "lines.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAM8mvxHJPj3"
   },
   "source": [
    "# Def. Get Summary Statistics for every model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666199526446,
     "user": {
      "displayName": "'ASIFMAHMUD' IUB",
      "userId": "12339450445858385211"
     },
     "user_tz": -360
    },
    "id": "r9dvKzzc4pdQ"
   },
   "outputs": [],
   "source": [
    "def get_model_statistics_summary(model_path,path_encoder_parameters,path_encoder_dictionary,path_decoder_parameters,path_decoder_dictionary, encoderPath, decoderPath ):\n",
    "\n",
    "################################## START  ##################################\n",
    "    reconstructed_model = keras.models.load_model(model_path)\n",
    "    plot_model(reconstructed_model, to_file='modelsummary.png', show_shapes=True, show_layer_names=True)\n",
    "    reconstructed_model.summary()\n",
    "\n",
    "\n",
    "    ## Load Dictionaries and Parameters \n",
    "    path_encoder_parameters= path_encoder_parameters\n",
    "    path_encoder_dictionary= path_encoder_dictionary\n",
    "    path_decoder_parameters= path_decoder_parameters\n",
    "    path_decoder_dictionary= path_decoder_dictionary\n",
    "\n",
    "    # loading\n",
    "    with open(path_encoder_parameters, 'rb') as handle:\n",
    "        encoder_parameters = pickle.load(handle)\n",
    "\n",
    "    # loading\n",
    "    with open(path_encoder_dictionary, 'rb') as handle:\n",
    "        encoder_dictionary = pickle.load(handle)\n",
    "\n",
    "    # loading\n",
    "    with open(path_decoder_parameters, 'rb') as handle:\n",
    "        decoder_parameters= pickle.load(handle)\n",
    "\n",
    "    # loading\n",
    "    with open(path_decoder_dictionary, 'rb') as handle:\n",
    "        decoder_dictionary = pickle.load(handle)    \n",
    "\n",
    "    print(encoder_parameters)\n",
    "    # encoder_dictionary\n",
    "    print(decoder_parameters)\n",
    "    # decoder_dictionary\n",
    "\n",
    "    encoder_inputs = reconstructed_model.input[0]  # input_1\n",
    "    encoder_outputs, state_h_enc, state_c_enc = reconstructed_model.layers[4].output  # lstm_1\n",
    "    encoder_states = [state_h_enc, state_c_enc]\n",
    "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "    latent_dim = 256  # Note: may be need to save in drive as well\n",
    "\n",
    "\n",
    "    num_decoder_tokens =decoder_parameters['num_decoder_tokens']\n",
    "    max_output_length= decoder_parameters['max_decoder_seq_length']\n",
    "    max_input_length= encoder_parameters['max_encoder_seq_length']\n",
    "\n",
    "    encoder_word_dict=encoder_dictionary\n",
    "    decoder_word_dict= decoder_dictionary\n",
    "\n",
    "\n",
    "    decoder_inputs = Input(shape=( max_output_length , ))\n",
    "    decoder_embedding = Embedding( num_decoder_tokens, 256 , mask_zero=True) (decoder_inputs)\n",
    "\n",
    "    decoder_lstm = LSTM( 256 , return_state=True , return_sequences=True , recurrent_dropout=0.2 , dropout=0.2)\n",
    "    decoder_dense = Dense( num_decoder_tokens , activation=tf.keras.activations.softmax ) \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    def make_inference_models():\n",
    "        \n",
    "            encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "            \n",
    "            decoder_state_input_h = tf.keras.layers.Input(shape=( 256,))\n",
    "            decoder_state_input_c = tf.keras.layers.Input(shape=( 256 ,))\n",
    "            \n",
    "            decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "            \n",
    "            decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "                decoder_embedding , initial_state=decoder_states_inputs)\n",
    "            decoder_states = [state_h, state_c]\n",
    "            decoder_outputs = decoder_dense(decoder_outputs)\n",
    "            decoder_model = tf.keras.models.Model(\n",
    "                [decoder_inputs] + decoder_states_inputs,\n",
    "                [decoder_outputs] + decoder_states)\n",
    "            \n",
    "            return encoder_model , decoder_model\n",
    "\n",
    "\n",
    "    enc_model , dec_model = make_inference_models()\n",
    "\n",
    "\n",
    "    # Test Previous Model\n",
    "\n",
    "\n",
    "    encoderPath= encoderPath\n",
    "    decoderPath= decoderPath\n",
    "\n",
    "    # loading\n",
    "\n",
    "    enc_model =  load_model(encoderPath)\n",
    "    dec_model  =  load_model(decoderPath)\n",
    "\n",
    "\n",
    "\n",
    "################################## END  ##################################\n",
    "\n",
    "    ## Get sentences to test the model\n",
    "\n",
    "    # lines = pd.read_table( 'hin.txt' , names=[ 'eng' , 'hindi' ] )\n",
    "    # lines.reset_index( level=0 , inplace=True )\n",
    "    # lines.rename( columns={ 'index' : 'eng' , 'eng' : 'hindi' , 'hindi' : 'c' } , inplace=True )\n",
    "    # lines = lines.drop( 'c' , 1 )  \n",
    "\n",
    "    sample_sentences= lines[-10:]\n",
    "    sample_sentences\n",
    "\n",
    "    # Reference Token \n",
    "\n",
    "    reference_tokens=[]\n",
    "\n",
    "    for line in sample_sentences['eng']:\n",
    "        # print( line.split() ) \n",
    "        reference_tokens.append( line.split() )\n",
    "\n",
    "    df = pd.DataFrame(      columns=['reference', 'candidate', 'bleu_score'],  )\n",
    "\n",
    "    df[\"reference\"]= reference_tokens\n",
    "\n",
    "    ####### START Calculate Cosine Similarity for two sentences\n",
    "    scores=[]\n",
    "    for line in sample_sentences['eng']:\n",
    "        translation= translate_sentence(line, enc_model,dec_model, encoder_word_dict,  decoder_word_dict , max_input_length, preprocessing)\n",
    "        result= get_cosine_val (translation, line)\n",
    "        scores.append(result)\n",
    "\n",
    "    df[\"cosine_similarity\"]= scores    ## Cosine score calculated\n",
    "\n",
    "    ####### END Calculate Cosine Similarity for two sentences\n",
    "    \n",
    "\n",
    "    # Candidate Tokens \n",
    "    candidate_tokens=[]\n",
    "\n",
    "\n",
    "    for line in sample_sentences['hindi']:\n",
    "    \n",
    "        result= translate_sentence(line, enc_model,dec_model, encoder_word_dict,  decoder_word_dict , max_input_length, preprocessing)\n",
    "        temp =result.split()\n",
    "        temp= temp[:-1]\n",
    "        candidate_tokens.append(temp)\n",
    "        \n",
    "\n",
    "    df[\"candidate\"]= candidate_tokens\n",
    "\n",
    "\n",
    "    ## Calculate BLEU score\n",
    "\n",
    "    scores=get_BLEU_score(df,sentence_bleu)\n",
    "    df[\"bleu_score\"]= scores    ## BLEU score calculated\n",
    "\n",
    "    ## Calcualte ROUGE score\n",
    "    scores= get_ROUGE_score(df, pd, tf,text)\n",
    "    df[\"rouge_score\"]= scores  ## ROUGE score calculated\n",
    "\n",
    "    rouge_metric= pd.DataFrame.from_records(df['rouge_score'])\n",
    "\n",
    "    average_f_measure = rouge_metric['f_measure'].mean()\n",
    "    average_p_measure = rouge_metric['p_measure'].mean()\n",
    "    average_r_measure = rouge_metric['r_measure'].mean()\n",
    "    average_cosine= df['cosine_similarity'].mean()\n",
    "    average_bleu= df['bleu_score'].mean()\n",
    "\n",
    "    ## return BLEU and ROUGE score to the list \n",
    "    return [average_f_measure, average_p_measure,average_r_measure, average_cosine, average_bleu]\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBiGboDFKJyy"
   },
   "source": [
    "# Get Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 73541,
     "status": "ok",
     "timestamp": 1666199606624,
     "user": {
      "displayName": "'ASIFMAHMUD' IUB",
      "userId": "12339450445858385211"
     },
     "user_tz": -360
    },
    "id": "USuXFNZ5AS_l",
    "outputId": "6adaa403-d0f7-4445-8fec-94b22e9cfee3"
   },
   "outputs": [],
   "source": [
    "\n",
    "stat=[]\n",
    "for item in model_list:\n",
    "\n",
    "    model_path= path+item+\"/model.h5\" \n",
    "    path_encoder_parameters= path+item+\"/parameters/encoder_parameters.pickle\" \n",
    "    path_encoder_dictionary= path+item+\"/dictionaries/encoder_dictionary.pickle\" \n",
    "    path_decoder_parameters= path+item+\"/parameters/decoder_parameters.pickle\" \n",
    "    path_decoder_dictionary= path+item+\"/dictionaries/decoder_dictionary.pickle\" \n",
    "    encoderPath= path+item+\"/enc_model.h5\" \n",
    "    decoderPath= path+item+\"/dec_model.h5\" \n",
    "    # print(model_path, path_encoder_parameters,path_encoder_dictionary,path_decoder_parameters,path_decoder_dictionary,encoderPath,decoderPath)\n",
    "    result= get_model_statistics_summary(model_path, path_encoder_parameters,path_encoder_dictionary,path_decoder_parameters,path_decoder_dictionary,encoderPath,decoderPath)\n",
    "    result.insert(0, item)\n",
    "    stat.append(result)\n",
    "    print(result)\n",
    "\n",
    "table =pd.DataFrame(columns=[\"Dataset Size\",\"average_f_measure\", \"average_p_measure\",\"average_r_measure\", \"average_cosine\" ,\"average_bleu\"], data=stat)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1666199687866,
     "user": {
      "displayName": "'ASIFMAHMUD' IUB",
      "userId": "12339450445858385211"
     },
     "user_tz": -360
    },
    "id": "5xjS602GsIBG",
    "outputId": "766c75c0-ca3e-494f-c879-28e72614c692"
   },
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70wi_tlCG4Mn"
   },
   "source": [
    "#Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1666199694316,
     "user": {
      "displayName": "'ASIFMAHMUD' IUB",
      "userId": "12339450445858385211"
     },
     "user_tz": -360
    },
    "id": "xtykWgaEGRNm",
    "outputId": "74e6f3c2-3416-4051-aa6d-a1e7515d1482"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "#,figsize=(10,15)\n",
    "\n",
    "table.plot.bar(x=\"Dataset Size\",figsize=(15,10))\n",
    "plot.show(block=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1666197998339,
     "user": {
      "displayName": "'ASIFMAHMUD' IUB",
      "userId": "12339450445858385211"
     },
     "user_tz": -360
    },
    "id": "AKB9tf1sIYpN"
   },
   "outputs": [],
   "source": [
    "table.plot.bar(x=\"Dataset Size\",y=\"average_bleu\")\n",
    "plot.yscale(\"log\")\n",
    "plot.gca().yaxis.set_major_formatter(ScalarFormatter())\n",
    "\n",
    "plot.show(block=True);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJ9eXALYPvUlVE9aDtkF0t",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Display Kernel Name is Kanye ",
   "language": "python",
   "name": "west-kanye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "231fa661f6864ef19e499bbd2782d03ff99f363f5ebfe416ba9cf7c065dc127b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
