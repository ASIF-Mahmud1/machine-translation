{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from statistics import mean\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "\n",
    "def handle_helper_functions():\n",
    "    print(sys.path)\n",
    "    directory_path = os.path.abspath(os.path.join('../../helper'))\n",
    "    if directory_path not in sys.path:\n",
    "        sys.path.append(directory_path)    \n",
    "\n",
    "    translation_path=os.path.abspath(os.path.join('../../utils')) \n",
    "    if translation_path not in sys.path:\n",
    "        sys.path.append(translation_path)   \n",
    "    sys.path.append('/Users/learn/Desktop/Projects/machine-translation/test/helper')                                       \n",
    "    sys.path.append('/Users/learn/Desktop/Projects/machine-translation/utils')\n",
    "    sys.path.append('/Users/learn/Desktop/Projects/machine-translation/data')\n",
    "\n",
    "\n",
    "    lstm_helper_path = os.path.abspath(os.path.join('./create-model/lstm/'))\n",
    "    if lstm_helper_path not in sys.path:\n",
    "        sys.path.append(lstm_helper_path)    \n",
    "\n",
    "    print(sys.path)\n",
    "    \n",
    "\n",
    "handle_helper_functions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Path of Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import tensorflow_text as text\n",
    "from scoreTest import get_cosine_val, get_BLEU_score, get_ROUGE_score\n",
    "from translate import  translate_sentence\n",
    "from preprocessing_text import removePunctuation, toLowercase\n",
    "from iit_dataset import createDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import string\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import LSTM,Dense,Embedding,RepeatVector,TimeDistributed\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    # Print with Markdowns    \n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size=15000\n",
    "\n",
    "pool_oftexts, pairs =createDataset(data_size=data_size, type=\"train\")\n",
    "dataset= pool_oftexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sentences will be used\n",
    "# Limit the sentences to 10.000 on Kaggle to avoid exceding the\n",
    "# available RAM space\n",
    "# Build a generator to avoid this issue\n",
    "\n",
    "total_sentences = 1000\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# What proportion of the sentences will be used for the test set\n",
    "test_proportion = 0.1\n",
    "train_test_threshold = int( (1-test_proportion) * total_sentences)\n",
    "\n",
    "printmd(f'## {total_sentences} \"parallel sentences\" will be loaded (original sentence + its translation)')\n",
    "printmd(f'## {train_test_threshold} \"parallel sentences\" will be used to train the model')\n",
    "printmd(f'## {total_sentences-train_test_threshold} \"parallel sentences\" will be used to test the model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source and Target Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_src=0\n",
    "idx_tar = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "dataset = dataset.sample(frac=1, random_state=0)\n",
    "dataset.iloc[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    # Clean the string\n",
    "    string = string.replace(\"\\u202f\",\" \") # Replace no-break space with space\n",
    "    string = string.lower()\n",
    "    \n",
    "    # Delete the punctuation and the numbers\n",
    "    for p in punctuation + \"«»\" + \"0123456789\":\n",
    "        string = string.replace(p,\" \")\n",
    "        \n",
    "    string = re.sub('\\s+',' ', string)\n",
    "    string = string.strip()\n",
    "           \n",
    "    return string\n",
    "\n",
    "# Clean the sentences\n",
    "dataset[\"eng\"] = dataset[\"eng\"].apply(lambda x: clean(x))\n",
    "dataset[\"hindi\"] = dataset[\"hindi\"].apply(lambda x: clean(x))\n",
    "\n",
    "# Select one part of the dataset\n",
    "dataset = dataset.values\n",
    "dataset = dataset[:total_sentences]\n",
    "\n",
    "# split into train/test\n",
    "train, test = dataset[:train_test_threshold], dataset[train_test_threshold:]\n",
    "\n",
    "# Define the name of the source and of the target\n",
    "# This will be used in the outputs of this notebook\n",
    "source_str, target_str = \"Hindi\", \"English\"\n",
    "\n",
    "# The index in the numpy array of the source and of the target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset[1000:1010])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    # fit a tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    " \n",
    "\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # encode and pad sequences\n",
    "    X = tokenizer.texts_to_sequences(lines) # integer encode sequences\n",
    "    X = pad_sequences(X, maxlen=length, padding='post') # pad sequences with 0 values\n",
    "    return X\n",
    " \n",
    "def encode_output(sequences, vocab_size):\n",
    "    # one hot encode target sequence\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = np.array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y\n",
    " \n",
    "# Prepare target tokenizer\n",
    "tar_tokenizer = create_tokenizer(dataset[:, idx_tar]) #save\n",
    "tar_vocab_size = len(tar_tokenizer.word_index) + 1  #save\n",
    "tar_length = 15  #save\n",
    "printmd(f'\\nTarget ({target_str}) Vocabulary Size: {tar_vocab_size}')\n",
    "printmd(f'Target ({target_str}) Max Length: {tar_length}')\n",
    "\n",
    "# Prepare source tokenizer\n",
    "src_tokenizer = create_tokenizer(dataset[:, idx_src])  #save\n",
    "src_vocab_size = len(src_tokenizer.word_index) + 1  #save\n",
    "src_length = 15  #save\n",
    "printmd(f'\\nSource ({source_str}) Vocabulary Size: {src_vocab_size}')\n",
    "printmd(f'Source ({source_str}) Max Length: {src_length}\\n')\n",
    " \n",
    "# Prepare training data\n",
    "trainX = encode_sequences(src_tokenizer, src_length, train[:, idx_src])\n",
    "trainY = encode_sequences(tar_tokenizer, tar_length, train[:, idx_tar])\n",
    "trainY = encode_output(trainY, tar_vocab_size)\n",
    "\n",
    "# Prepare test data\n",
    "testX = encode_sequences(src_tokenizer, src_length, test[:, idx_src])\n",
    "testY = encode_sequences(tar_tokenizer, tar_length, test[:, idx_tar])\n",
    "testY = encode_output(testY, tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    " \n",
    "# Create model\n",
    "model = create_model(src_vocab_size, tar_vocab_size, src_length, tar_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "history = model.fit(trainX, \n",
    "          trainY, \n",
    "          epochs=200,#200 \n",
    "          batch_size=64, \n",
    "          validation_split=0.1, \n",
    "          verbose=1,\n",
    "          callbacks=[\n",
    "                        EarlyStopping(\n",
    "                        monitor='val_loss',\n",
    "                        patience=10,\n",
    "                        restore_best_weights=True\n",
    "                    )\n",
    "            ])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# save model in computer '/Users/learn/Desktop/Projects/machine-translation/data'\n",
    "# model.save()\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Previously Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# model = keras.models.load_model('lstm_model')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    "    # map an integer to a word\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    " \n",
    "def predict_seq(model, tokenizer, source):\n",
    "    # generate target from a source sequence\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [np.argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)\n",
    "    \n",
    "def create_dataframe_to_score(model, tokenizer, sources, raw_dataset):\n",
    "    # Get the bleu score of a model\n",
    "    actual, predicted, actual_rouge , cosine_value_list= [], [],[], []\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_seq(model, tar_tokenizer, source)\n",
    "        raw_src, raw_target = raw_dataset[i]\n",
    "        actual.append([raw_target.split()])\n",
    "        actual_rouge.append(raw_target.split())\n",
    "        predicted.append(translation.split())\n",
    "        #######################################################################\n",
    "                    ####   Calculate Cosine Value   ####\n",
    "\n",
    "        cosine_value= get_cosine_val (translation,raw_target )\n",
    "        cosine_value_list.append(cosine_value)\n",
    "        #######################################################################\n",
    "        # print(\"predicted \",translation.split())    \n",
    "   \n",
    "    average_cosine= mean(cosine_value_list)\n",
    "    return actual, predicted, actual_rouge, average_cosine\n",
    "\n",
    "actual, predicted, actual_rouge, average_cosine =create_dataframe_to_score(model, tar_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(actual, predicted):\n",
    "    # Get the bleu score of a model\n",
    "    bleu_dic = {}\n",
    "    bleu_dic['bleu-1-grams'] = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
    "    bleu_dic['bleu-1-2-grams'] = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
    "    bleu_dic['bleu-1-3-grams'] = corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n",
    "    bleu_dic['bleu-1-4-grams'] = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    \n",
    "    return bleu_dic\n",
    "\n",
    "def calculate_ROUGE(actual, predicted):\n",
    "    hypotheses = tf.ragged.constant(predicted)\n",
    "    references = tf.ragged.constant(actual)\n",
    "\n",
    "    rouge_test= text.metrics.rouge_l(hypotheses, references)\n",
    "    f_measure_list= rouge_test.f_measure\n",
    "    p_measure_list= rouge_test.p_measure\n",
    "    r_measure_list= rouge_test.r_measure\n",
    "  \n",
    "\n",
    "    f_measure_average= (f_measure_list.numpy()).mean()\n",
    "    p_measure_average= (p_measure_list.numpy()).mean()\n",
    "    r_measure_average=(r_measure_list.numpy()).mean()\n",
    "    return { \"f_measure_average\":f_measure_average, \"p_measure_average\":p_measure_average, \"r_measure_average\":r_measure_average  }  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result= get_cosine_val (actual[0], predicted[0])\n",
    "\n",
    "# result= get_cosine_val (\"I love cow\",\"i love grass\" )\n",
    "# result\n",
    "\n",
    "actual[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the BLEU Score\n",
    "# bleu_train = bleu_score(model, tar_tokenizer, trainX, train)\n",
    "bleu_test = bleu_score(actual, predicted)\n",
    "rouge_test = calculate_ROUGE(actual=actual_rouge, predicted=predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rouge_test)\n",
    "print(bleu_test)\n",
    "print(average_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(x = bleu_train.keys(), height = bleu_train.values())\n",
    "# plt.title(\"BLEU Score with the training set\")\n",
    "# plt.ylim((0,1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = bleu_test.keys(), height = bleu_test.values())\n",
    "plt.title(\"BLEU Score with the test set\")\n",
    "plt.ylim((0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = rouge_test.keys(), height = rouge_test.values())\n",
    "plt.title(\"ROUGE Score with the test set\")\n",
    "plt.ylim((0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = \"cosine_average\", height = average_cosine)\n",
    "plt.title(\"Cosine Score with the test set\")\n",
    "plt.ylim((0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[\"Dataset Size\", *rouge_test.keys(), \"cosine_similarity\", *bleu_test.keys()]\n",
    "\n",
    "values=[total_sentences,  *rouge_test.values(), average_cosine, *bleu_test.values() ]\n",
    "\n",
    "table =pd.DataFrame(columns=keys, data=[values])\n",
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "#,figsize=(10,15)\n",
    "\n",
    "table.plot.bar(x=\"Dataset Size\",figsize=(15,10))\n",
    "plot.show(block=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save Model and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../model/lstm/1000/lstm_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../model/lstm/1000/lstm_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x15fea3070> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x15ffa01f0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update  [[1.00000000e+004 7.64712036e-001 7.75633931e-001 7.64969170e-001\n",
      "  7.86634681e-001 7.47674297e-001 6.53796439e-001 5.93642770e-001\n",
      "  4.87186522e-001]\n",
      " [1.00000000e+003 3.24609280e-002 9.00000036e-002 2.00046729e-002\n",
      "  5.06093138e-002 1.61748980e-003 6.93011957e-157 1.81453755e-187\n",
      "  1.43446621e-233]\n",
      " [1.00000000e+003 3.24609280e-002 9.00000036e-002 2.00046729e-002\n",
      "  5.06093138e-002 1.61748975e-003 6.93011957e-157 1.81453755e-187\n",
      "  1.43446621e-233]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def saveAnalytics(analytics_table):\n",
    "    import os\n",
    "    import json\n",
    "    import time\n",
    "    fname = \"../../analytics/lstm/\"+\"analytics.json\"\n",
    "\n",
    "    if os.path.exists(fname):\n",
    "        # read existing file and append new data\n",
    "        with open(fname,\"r\") as f:\n",
    "            df = pd.read_json(fname)\n",
    "            new_data=(analytics_table.to_numpy())[0] \n",
    "            df.loc[len(df.index)] = new_data # add another row\n",
    "            print(\"Update \",df.to_numpy() )\n",
    "            df.to_json(r'../../analytics/lstm/'+\"analytics.json\",orient='records')\n",
    "    else:\n",
    "        # create new json\n",
    "        print(\"Create \",analytics_table )\n",
    "        analytics_table.to_json(r'../../analytics/lstm/'+\"analytics.json\",orient='records')\n",
    "\n",
    "\n",
    "def save_models_and_parameters(total_sentences,model,src_tokenizer, tar_tokenizer, src_length, tar_length, src_vocab_size,tar_vocab_size, analytics_table ):\n",
    "    model_name = str(total_sentences)\n",
    "    path=\"../../model/lstm/\"+model_name+\"/\"\n",
    "    \n",
    "    src_parameters={\n",
    "        'src_length': src_length,\n",
    "        'src_vocab_size': src_vocab_size,\n",
    "    }\n",
    "    src_tokenizer= src_tokenizer\n",
    "\n",
    "    target_parameters={\n",
    "        'target_length': tar_length,\n",
    "        'target_vocab_size': tar_vocab_size,\n",
    "    }\n",
    "    target_tokenizer= tar_tokenizer\n",
    "\n",
    "    model.save(path+'lstm_model' ) \n",
    "    with open(path+'src_parameters.pickle', 'wb') as handle:\n",
    "        pickle.dump(src_parameters, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(path+'src_tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(src_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(path+'target_parameters.pickle', 'wb') as handle:\n",
    "        pickle.dump(target_parameters, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(path+'target_tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(target_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    saveAnalytics(analytics_table=analytics_table)\n",
    "   \n",
    "\n",
    "   \n",
    "save_models_and_parameters(total_sentences,model,src_tokenizer, tar_tokenizer, src_length, tar_length, src_vocab_size,tar_vocab_size, table )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tears",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "231fa661f6864ef19e499bbd2782d03ff99f363f5ebfe416ba9cf7c065dc127b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
